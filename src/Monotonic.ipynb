{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from pystan import StanModel\n",
    "n_jobs = 4\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_color_codes()\n",
    "import pickle\n",
    "%pylab inline\n",
    "\n",
    "models = pickle.load(open('model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model_inference(model_name, Y=None, generated_data='data_latent', models=models, \n",
    "                         generator_iter=50, inference_iter=1000):\n",
    "    \n",
    "    if Y is None:\n",
    "        Y = pd.DataFrame(rand(100,5))\n",
    "    stan_data = {**models[model_name]['stan_data_creator'](Y, run_inference=False), \n",
    "                 **models[model_name]['parameter_priors']} \n",
    "\n",
    "    generated_example = models[model_name]['stan_model'].sampling(data=stan_data, n_jobs=n_jobs,iter=generator_iter)\n",
    "\n",
    "    sample = 20\n",
    "    generated_parameters = {}\n",
    "    for parameter in models[model_name]['model_parameters']:\n",
    "        generated_parameters[parameter] = generated_example[parameter][sample]\n",
    "\n",
    "    generated_data = pd.DataFrame(generated_example[generated_data][sample])\n",
    "\n",
    "    stan_data = {**models[model_name]['stan_data_creator'](generated_data, run_inference=True), \n",
    "                 **models[model_name]['parameter_priors']} \n",
    "    model_fit = models[model_name]['stan_model'].sampling(data=stan_data, n_jobs=n_jobs,iter=inference_iter)\n",
    "\n",
    "    true_parameters_inferred_scores = {}\n",
    "    true_parameters_inferred_score_within_95CI = 0\n",
    "    n_parameters = 0\n",
    "    from scipy.stats import percentileofscore\n",
    "    \n",
    "    for parameter in models[model_name]['model_parameters']:\n",
    "        parameter_samples = model_fit[parameter]\n",
    "        if parameter_samples.ndim>2:\n",
    "            parameter_samples = parameter_samples.reshape(parameter_samples.shape[0], \n",
    "                                                          prod(parameter_samples.shape[1:]))\n",
    "        true_parameters_inferred_scores[parameter] = array(list(map(percentileofscore, \n",
    "                                                             parameter_samples.T, \n",
    "                                                             generated_parameters[parameter].ravel())))\n",
    "        true_parameters_inferred_score_within_95CI += sum((true_parameters_inferred_scores[parameter]>2.5) & \n",
    "                                                          (true_parameters_inferred_scores[parameter]<97.5)\n",
    "                                                         )\n",
    "        n_parameters += true_parameters_inferred_scores[parameter].size\n",
    "    return true_parameters_inferred_score_within_95CI/n_parameters#, true_parameters_inferred_score_within_95CI\n",
    "\n",
    "from pystan.misc import _summary, _array_to_table\n",
    "def _print_stanfit(fit, pars=None, probs=(0.025, 0.25, 0.5, 0.75, 0.975), digits_summary=2):\n",
    "        if fit.mode == 1:\n",
    "            return \"Stan model '{}' is of mode 'test_grad';\\n\"\\\n",
    "                   \"sampling is not conducted.\".format(fit.model_name)\n",
    "        elif fit.mode == 2:\n",
    "            return \"Stan model '{}' does not contain samples.\".format(fit.model_name)\n",
    "        if pars is None:\n",
    "            pars = fit.sim['pars_oi']\n",
    "            fnames = fit.sim['fnames_oi']\n",
    "\n",
    "        n_kept = [s - w for s, w in zip(fit.sim['n_save'], fit.sim['warmup2'])]\n",
    "        header = \"\"#Inference for Stan model: {}.\\n\".format(fit.model_name)\n",
    "        header += \"{} chains, each with iter={}; warmup={}; thin={}; \\n\"\n",
    "        header = header.format(fit.sim['chains'], fit.sim['iter'], fit.sim['warmup'],\n",
    "                               fit.sim['thin'], sum(n_kept))\n",
    "        header += \"post-warmup draws per chain={}, total post-warmup draws={}.\\n\\n\"\n",
    "        header = header.format(n_kept[0], sum(n_kept))\n",
    "        footer = \"\\n\\nSamples were drawn using {} at {}.\\n\"\\\n",
    "#             \"For each parameter, n_eff is a crude measure of effective sample size,\\n\"\\\n",
    "#             \"and Rhat is the potential scale reduction factor on split chains (at \\n\"\\\n",
    "#             \"convergence, Rhat=1).\"\n",
    "        sampler = fit.sim['samples'][0]['args']['sampler_t']\n",
    "        date = fit.date.strftime('%c')  # %c is locale's representation\n",
    "        footer = footer.format(sampler, date)\n",
    "        s = _summary(fit, pars, probs)\n",
    "        body = _array_to_table(s['summary'], s['summary_rownames'],\n",
    "                               s['summary_colnames'], digits_summary)\n",
    "        return header + body + footer\n",
    "\n",
    "def plot_time_series_inference(model_fit, var='data_latent', x=None,\n",
    "                               ax=None, ind=0, **kwargs):\n",
    "    from scipy.stats import scoreatpercentile\n",
    "    ci_thresholds = [2.5, 25, 75, 97.5]\n",
    "    if len(model_fit[var].shape)<3:\n",
    "        data = model_fit[var]\n",
    "    else:\n",
    "        data = model_fit[var][:,:,ind]\n",
    "    CIs = scoreatpercentile(data, ci_thresholds, axis=0)\n",
    "    CIs = pd.DataFrame(data=CIs.T, columns=ci_thresholds)\n",
    "    if ax is None:\n",
    "        ax=gca()\n",
    "    if x is None:\n",
    "        x = arange(data.shape[1])\n",
    "    ax.fill_between(x, CIs[2.5], CIs[97.5],alpha=.5, **kwargs)\n",
    "    ax.fill_between(x, CIs[25], CIs[75], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_42a67baa9f57f5285fb17bdb74d9a8e5 NOW.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Y_delta~N(mu,sigma) T[0,], missing data'\n",
    "models[model_name] = {}\n",
    "\n",
    "models[model_name]['code'] = \"\"\"\n",
    "functions {\n",
    "  // lower bound is a, upper bound is b, rv is x, mean is mu, sd is sigma\n",
    "  \n",
    "  real alpha(real a, real mu, real sigma) {\n",
    "    real out;\n",
    "    out = (a==negative_infinity())? negative_infinity(): (a - mu)/sigma;\n",
    "    return(out);\n",
    "  }\n",
    "  real beta(real b, real mu, real sigma) {\n",
    "    real out;\n",
    "    out = (b==positive_infinity())? positive_infinity(): (b - mu)/sigma;\n",
    "    return(out);\n",
    "  }\n",
    "  real Z(real a, real b, real mu, real sigma) {\n",
    "    return(normal_cdf(beta(b, mu, sigma), 0.0, 1.0) - normal_cdf(alpha(a, mu, sigma), 0.0, 1.0));\n",
    "  }\n",
    "  vector truncnorm_ng(vector p, real a, real b, real location, real scale) {\n",
    "    vector[rows(p)] out;\n",
    "    real tmp_Z;\n",
    "    real tmp_alpha;\n",
    "    \n",
    "    tmp_alpha = normal_cdf(alpha(a, location, scale), 0, 1);\n",
    "    tmp_Z = normal_cdf(beta(b, location, scale), 0, 1) - tmp_alpha;\n",
    "    for(i in 1:rows(p)) {\n",
    "      out[i] = inv_Phi(tmp_alpha + p[i]*tmp_Z)*scale + location;\n",
    "    }\n",
    "    return(out);\n",
    "  }\n",
    "}\n",
    "data {\n",
    "  int T; // number of rows\n",
    "  int P; // number of columns\n",
    "  matrix[T, P] Y; // -999 for missing values\n",
    "  int run_inference;\n",
    "  \n",
    "  //priors\n",
    "  real mu_location; \n",
    "  real mu_scale;\n",
    "  real sigma_location;\n",
    "  real sigma_scale;\n",
    "    \n",
    "}\n",
    "parameters {\n",
    "  matrix[T, P] z;\n",
    "  vector[P] mu;\n",
    "  vector<lower = 0>[P] sigma;\n",
    "  corr_matrix[P] L_omega;\n",
    "}\n",
    "transformed parameters {\n",
    "  matrix[T, P] theta;\n",
    "  matrix[T, P] theta_constrained;\n",
    "  matrix[T, P] data_latent;\n",
    "  // use simple reparameterization to turn z into theta\n",
    "  theta = z*cholesky_decompose(L_omega);\n",
    "  for(p in 1:P){\n",
    "    theta_constrained[1:T, p] = truncnorm_ng(Phi(col(theta, p)), 0, positive_infinity(), mu[p], sigma[p]);\n",
    "  }\n",
    "  \n",
    "  //\n",
    "  for(t in 1:T) {\n",
    "    for(p in 1:P) {\n",
    "      data_latent[t, p] = sum(theta_constrained[1:t, p]);\n",
    "    }\n",
    "  }\n",
    "}\n",
    "model {\n",
    "  // priors\n",
    "  to_vector(z) ~ normal(0, 1);\n",
    "  mu ~ normal(mu_location, mu_scale);\n",
    "  sigma ~ normal(sigma_location, sigma_scale);\n",
    "  L_omega ~ lkj_corr(3);\n",
    "  \n",
    "  if(run_inference==1) {\n",
    "    for(p in 1:P) {\n",
    "    real tmp;\n",
    "    tmp = 0.0;\n",
    "    for(t in 1:T) {\n",
    "      if(Y[t,p]>-998) {\n",
    "        Y[t,p] ~ normal(data_latent[t, p], .1) T[tmp,];\n",
    "        tmp = Y[t,p];\n",
    "      }\n",
    "     }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "models[model_name]['stan_model'] = StanModel(model_code=models[model_name]['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_delta~N(mu,sigma) T[0,], missing data\n",
      "Portion of parameters' true values within the 95% CI: 0.500\n"
     ]
    }
   ],
   "source": [
    "models[model_name]['parameter_priors'] = {\n",
    "    'mu_location': 1,\n",
    "    'mu_scale': .1,\n",
    "    'sigma_location': 0,\n",
    "    'sigma_scale': .1,\n",
    "    }\n",
    "\n",
    "models[model_name]['model_parameters'] = unique([i.rsplit('_', 1)[0] for i in models[model_name]['parameter_priors'].keys()])\n",
    "\n",
    "def stan_data_creator(Y,run_inference=True):\n",
    "    stan_data = {'Y':Y.fillna(-999),\n",
    "                 'T': Y.shape[0],\n",
    "                 'P': Y.shape[1],\n",
    "                 'run_inference': int(run_inference),\n",
    "                }\n",
    "    return stan_data\n",
    "\n",
    "models[model_name]['stan_data_creator'] = stan_data_creator\n",
    "\n",
    "print(model_name)\n",
    "print(\"Portion of parameters' true values within the 95%% CI: %.3f\"%(test_model_inference(model_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame(rand(100,5))\n",
    "stan_data = {**models[model_name]['stan_data_creator'](Y, run_inference=False), \n",
    "             **models[model_name]['parameter_priors']} \n",
    "\n",
    "generated_example = models[model_name]['stan_model'].sampling(data=stan_data, n_jobs=n_jobs,iter=50)\n",
    "\n",
    "sample = 20\n",
    "generated_parameters = {}\n",
    "for parameter in models[model_name]['model_parameters']:\n",
    "    generated_parameters[parameter] = generated_example[parameter][sample]\n",
    "\n",
    "generated_data = pd.DataFrame(generated_example['data_latent'][sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mu': array([ 1.07619537,  1.02342908,  1.10322936,  1.00029615,  0.88527371]),\n",
       " 'sigma': array([ 0.07630973,  0.13530527,  0.03096463,  0.16130493,  0.01960939])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_data = {**models[model_name]['stan_data_creator'](generated_data, run_inference=True), \n",
    "             **models[model_name]['parameter_priors']} \n",
    "model_fit = models[model_name]['stan_model'].sampling(data=stan_data, n_jobs=n_jobs,iter=1000)\n",
    "\n",
    "true_parameters_inferred_scores = {}\n",
    "true_parameters_inferred_score_within_95CI = 0\n",
    "n_parameters = 0\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "for parameter in models[model_name]['model_parameters']:\n",
    "    parameter_samples = model_fit[parameter]\n",
    "    if parameter_samples.ndim>2:\n",
    "        parameter_samples = parameter_samples.reshape(parameter_samples.shape[0], \n",
    "                                                      prod(parameter_samples.shape[1:]))\n",
    "    true_parameters_inferred_scores[parameter] = array(list(map(percentileofscore, \n",
    "                                                         parameter_samples.T, \n",
    "                                                         generated_parameters[parameter].ravel())))\n",
    "    true_parameters_inferred_score_within_95CI += sum((true_parameters_inferred_scores[parameter]>2.5) & \n",
    "                                                      (true_parameters_inferred_scores[parameter]<97.5)\n",
    "                                                     )\n",
    "    n_parameters += true_parameters_inferred_scores[parameter].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 chains, each with iter=1000; warmup=500; thin=1; \n",
      "post-warmup draws per chain=500, total post-warmup draws=2000.\n",
      "\n",
      "           mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "mu[0]      0.13    0.69   0.98  -1.12  -0.85   0.25   1.09   1.16      2    nan\n",
      "mu[1]      0.44    0.97   1.37  -1.88  -0.63   1.01   1.41   1.64      2    nan\n",
      "mu[2]      0.99    0.28   0.39   0.55   0.59   0.99   1.38    1.4      2    nan\n",
      "mu[3]      0.31     0.8   1.13  -1.48  -0.74   0.64   1.29   1.42      2    nan\n",
      "mu[4]      1.09    0.34   0.48   0.28   0.69   1.31   1.44   1.46      2    nan\n",
      "sigma[0]   1.51     0.3   0.42   0.89    1.1   1.58    1.9   1.96      2    nan\n",
      "sigma[1]   1.84    0.87   1.23   0.79   1.01   1.31   2.77   3.93      2    nan\n",
      "sigma[2]   1.54    0.24   0.34   1.06    1.2   1.59   1.87    1.9      2    nan\n",
      "sigma[3]   1.77    0.34   0.48   1.13   1.33   1.75   2.21   2.44      2    nan\n",
      "sigma[4]   1.04    0.38   0.53   0.18   0.55    1.2   1.49   1.56      2    nan\n",
      "\n",
      "Samples were drawn using NUTS at Mon May 29 07:40:05 2017.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(_print_stanfit(model_fit, pars=['mu', 'sigma']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_directory = '../data/'\n",
    "\n",
    "empirical_data = pd.read_csv(data_directory+'time_series.csv',index_col=0)\n",
    "empirical_data = empirical_data.reindex(arange(empirical_data.index[0],empirical_data.index[-1]+1))\n",
    "metadata = pd.read_csv(data_directory+'time_series_metadata.csv')\n",
    "\n",
    "target_tech_names = metadata.loc[(metadata['Type']=='Performance'), 'Name']\n",
    "empirical_time_series = log(empirical_data[target_tech_names])\n",
    "\n",
    "valid_time_series = sum(~empirical_time_series.loc[1976:].isnull())>3\n",
    "valid_domains = metadata.set_index('Name').loc[valid_time_series.index[valid_time_series]]['Domain'].unique()\n",
    "\n",
    "print(\"Number of valid domains: %i\"%valid_domains.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Y = empirical_time_series[valid_time_series].loc[1976:]\n",
    "any_data = Y.isnull().all(axis=0)\n",
    "Y = Y[any_data[~any_data].index]\n",
    "\n",
    "model_name = 'Y_delta~N(mu,sigma) T[0,], missing data'\n",
    "stan_data = {**models[model_name]['stan_data_creator'](Y), **models[model_name]['parameter_priors']} \n",
    "\n",
    "model_fit = models[model_name]['stan_model'].sampling(data=stan_data, n_jobs=n_jobs,iter=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
